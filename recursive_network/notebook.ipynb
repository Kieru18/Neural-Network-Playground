{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pewien słuchacz szkoły muzycznej ma w sobie niesamowity talent. Jednak przed jej ukończeniem wstrzymuje go jeden przedmiot - \"Kompozytorzy muzyki klasycznej\". Słuchacz ten, mając dość niepowodzeń w zdawaniu tego tematu, zwraca się do Was o pomoc.\n",
    "\n",
    "Zadanie polega na stworzeniu modelu rekurencyjnego, który będzie przewidywał kompozytora danego utworu klasycznego w oparciu o jego zapis w formie sekwencji akordów. Akordy znormalizowane zostały do klucza C-dur lub a-moll, w zależności od skali utworu (durowa/molowa).\n",
    "Dane przygotowane są w postaci pickle (https://docs.python.org/3/library/pickle.html), w których znajduje się lista krotek z sekwencjami i odpowiadającymi im klasami (kompozytorami), odpowiednio: {0: 'bach', 1: 'beethoven', 2: 'debussy', 3: 'scarlatti', 4: 'victoria'}. Dane treningowe znajdują się w pliku train.pkl. W pliku test_no_target.pkl znajdują się testowe sekwencje, dla których predykcje mają Państwo przewidzieć.\n",
    "\n",
    "Uwaga, utwory mogą mieć różne długości. Do stworzenia batchy dla przykładów różnej długości proszę wykorzystać omówiony na zajęciach padding i trenować z wykorzystaniem wyrównanych tensorów lub spakowanych sekwencji (PackedSequence).\n",
    "\n",
    "Bardzo proszę, żeby zwrócili Państwo archiwum zip, zgodnie z instrukcjami:\n",
    "- Archiwum powinno być nazwane {poniedzialek/piatek}_nazwisko1_nazwisko2.zip, bez nawiasów klamrowych przy dniu tygodnia\n",
    "- W archiwum proszę, bez zbędnych podfolderów, umieścić pliki ze swoim kodem i testowe predykcje nazwane {poniedzialek/piatek}_nazwisko1_nazwisko2.csv (lub nazwa drużyny), bez nawiasów klamrowych przy dniu tygodnia\n",
    "- Testowe predykcje powinny mieć kolejność zgodną z kolejnością sekwencji w picklu. Plik .csv nie powinien mieć nagłówka ani indeksów.\n",
    "\n",
    "Proszę zwracać uwagę na prawidłowe nazewnictwo oraz odpowiedni format zwracanych plików. Niedostosowanie się do wytycznych może spowodować nieuwzględnienie Państwa w rankingu i utratę punktów za osiągnięty wynik!\n",
    "Proszę także o udokumentowanie wykonanych eksperymentów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from collections import Counter\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.functional import F\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = './p5'\n",
    "MODEL_PATH = './model'\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 0.001\n",
    "TEST_RATIO = 0.2\n",
    "EPOCHS = 101\n",
    "\n",
    "MAX_DATASET_LEN = 750\n",
    "\n",
    "HIDDEN_DIM = 128\n",
    "INPUT_DIM = 1\n",
    "OUTPUT_DIM = 5\n",
    "DROPOUT_RATE = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{DATA_PATH}/train.pkl', 'rb') as file:\n",
    "    train_data = pickle.load(file)\n",
    "\n",
    "with open(f'{DATA_PATH}/test_no_target.pkl', 'rb') as file:\n",
    "    test_data = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MusicDataset(Dataset):\n",
    "    def __init__(self, data, max_len=None, is_train_dataset=True):\n",
    "        self.seq, self.labels = zip(*data)\n",
    "        self.max_len = max(len(s) for s in self.seq)\n",
    "        self.seq = [MusicDataset.pad_collate(self, seq) for seq in self.seq]\n",
    "        self.is_train_dataset = is_train_dataset\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.seq)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.seq[idx], self.labels[idx] if self.is_train_dataset else self.seq[idx]\n",
    "\n",
    "    @staticmethod\n",
    "    def pad_collate(self, seq, pad_value=0):\n",
    "        seq = torch.tensor(seq, dtype=torch.float32).unsqueeze(1)\n",
    "        padding = self.max_len - len(seq)\n",
    "        return F.pad(seq, (0, 0, 0, padding), mode=\"constant\", value=pad_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, validation_data = train_test_split(train_data, test_size=TEST_RATIO)\n",
    "\n",
    "train_dataset = MusicDataset(train_data, max_len=MAX_DATASET_LEN, is_train_dataset=True)\n",
    "test_dataset = MusicDataset([(seq, None) for seq in test_data], max_len=MAX_DATASET_LEN, is_train_dataset=False)\n",
    "validation_dataset = MusicDataset(validation_data, max_len=MAX_DATASET_LEN, is_train_dataset=True)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComposerClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, n_layers=1):\n",
    "        super(ComposerClassifier, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, \n",
    "                            hidden_dim, \n",
    "                            num_layers=n_layers, \n",
    "                            bidirectional=True, \n",
    "                            batch_first=True,\n",
    "                            dropout=DROPOUT_RATE)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
    "        self.dropout = nn.Dropout(DROPOUT_RATE)\n",
    "        self.batch_norm = nn.BatchNorm1d(hidden_dim * 2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        lstm_out, (hidden, cell) = self.lstm(x)\n",
    "        x = torch.cat((hidden[-2], hidden[-1]), dim=1)\n",
    "        x = self.batch_norm(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, train_labels = zip(*train_data)\n",
    "class_nums = Counter(train_labels)\n",
    "samples_num = sum(class_nums.values())\n",
    "class_weights = {cls: samples_num / num for cls, num in class_nums.items()}\n",
    "weights = torch.tensor([class_weights[ii] for ii in range(len(class_nums))], dtype=torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ComposerClassifier(INPUT_DIM, HIDDEN_DIM, OUTPUT_DIM).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/101 - Train Loss: 1.4220 - Train Accuracy: 0.4134\n",
      "Epoch 1/101 - Validation Loss: 1.1297 - Validation Accuracy: 0.5901\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [114], line 28\u001b[0m\n\u001b[1;32m     25\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     26\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 28\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m outputs \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mcpu()\n\u001b[1;32m     31\u001b[0m labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mcpu()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_validation_loss = float('inf')\n",
    "best_validation_accuracy = 0.0\n",
    "early_stop_num = 0\n",
    "early_stop_threshold = 5\n",
    "train_loss = []\n",
    "train_accuracy = []\n",
    "validation_loss = []\n",
    "validation_accuracy = []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for sequences, labels in train_loader:\n",
    "        sequences = sequences.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(sequences)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "\n",
    "        outputs = outputs.cpu()\n",
    "        labels = labels.cpu()\n",
    "\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    train_accuracy.append(correct / total)\n",
    "    train_loss.append(total_loss / len(train_loader))\n",
    "\n",
    "    print(f'Epoch {epoch + 1}/{EPOCHS} - Train Loss: {train_loss[-1]:.4f} - Train Accuracy: {train_accuracy[-1]:.4f}')\n",
    "\n",
    "    model.eval()\n",
    "    validation_loss_epoch = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for sequences, labels in validation_loader:\n",
    "            sequences = sequences.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(sequences)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            validation_loss_epoch += loss.item()\n",
    "\n",
    "            outputs = outputs.cpu()\n",
    "            labels = labels.cpu()\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    validation_accuracy_epoch = correct / total\n",
    "    validation_loss.append(validation_loss_epoch / len(validation_loader))\n",
    "    average_validation_loss = validation_loss_epoch / len(validation_loader)\n",
    "\n",
    "    print(f'Epoch {epoch + 1}/{EPOCHS} - Validation Loss: {average_validation_loss:.4f} - Validation Accuracy: {validation_accuracy_epoch:.4f}')\n",
    "    \n",
    "    if validation_accuracy_epoch > best_validation_accuracy:\n",
    "        best_validation_accuracy = validation_accuracy_epoch\n",
    "        torch.save(model.state_dict(), f'{MODEL_PATH}/best.pth')\n",
    "    \n",
    "print('Best accuracy:', best_validation_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(f'{MODEL_PATH}/best.pth'))\n",
    "\n",
    "predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    \n",
    "    for seq in test_loader:\n",
    "        seq = seq.to(device)\n",
    "        outputs = model(seq)\n",
    "        outputs = outputs.cpu()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "df = pd.DataFrame(predictions)\n",
    "df.to_csv('poniedzialek_kieruczenko_ziarek.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = range(1, EPOCHS + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(epochs, train_loss, label='Training Loss')\n",
    "plt.plot(epochs, validation_loss, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(epochs, train_accuracy, label='Training Accuracy')\n",
    "plt.plot(epochs, validation_accuracy, label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

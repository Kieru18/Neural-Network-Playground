{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mini projekt - modele generatywne\n",
    "Due May 13, 2024 4:00 PM\n",
    "\n",
    "Tym razem zadanie będzie polegało na stworzeniu modelu generatywnego który generował będzie nowe obrazki przedstawiające znaki drogowe. Do wyboru mają Państwo dowolny model generatywny (VAE, GAN, GLOW, VAEGAN, czy modele dyfuzyjne. W przypadku tych ostatnich polecam zapoznanie się z takim notebookiem: https://huggingface.co/learn/diffusion-course/en/unit1/3, jeżeli będą Państwo chętni to możemy wspólnie przejść przez niego w ramach laborek konsultacyjnych.\n",
    "\n",
    "Zbiór danych udostępniłem Państwu przez onedrive (trafic_32.zip) i ma taką samą strukturę jak poprzednio (zgodną z domyślnymi ustawieniami ImageFolderu). Znaki podzielone są na klasy, które jak najbardziej mogą Państwo wykorzystywać do generowania próbek. Tym razem zamiast predykcji proszę o zwrócenie mi kodu z implementacją eksperymentów i przykładowe 1000 próbek wygenerowanych za pomocą Państwa metody.\n",
    "Bardzo proszę żeby jak zwykle zwracali mi Państwo archiwum zip, jak zwykle proszę też o zastosowanie się do instrukcji:\n",
    "- Archiwum powinno być nazwane jak ostatnio poniedzialek/piatek_nazwisko1_nazwisko2.zip (lub nazwa drużyny)\n",
    "- W archiwum proszę bez zbędnych podfolderów umieścić pliki ze swoim kodem i wygenerowane obrazki nazwane odpowiednio poniedzialek_nazwisko1_nazwisko2.pt (lub nazwa drużyny)\n",
    "- Wygenerowane obrazki, proszę zapisywać po prostu w formie torchowego tensora (na cpu, po detach, czyli np. wykonując komendę torch.save(generated_imgs.cpu().detach(),\"poniedzialek_nazwisko1_nazwisko2.pt\") ). Tensor zgodnie z konwencją powinien mieć wymiary [1000, 3, 32, 32]\n",
    "\n",
    "Ewaluacja:\n",
    "- Wygenerowane obrazki porównywał będę do zbioru testowego za pomocą metryki Frechet Inception Distance o której wspominałem na ćwiczeniach. Jeżeli chcieliby Państwo z niej skorzystać do ewaluacji swoich modeli, to odsyłam do repozytorium z wygodną implementacją: https://github.com/mseitzer/pytorch-fid\n",
    "- W zbiorze testowym obrazki mają ten sam rozkład klas co w treningowym\n",
    "- Proszę pamiętać o denormalizacji próbek :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import zipfile\n",
    "\n",
    "# # Specify the path to the zip file\n",
    "# zip_file_path = '/content/trafic_32.zip'\n",
    "\n",
    "# # Specify the directory to extract the contents to\n",
    "# extract_dir = '/content/data/'\n",
    "\n",
    "# # Extract the zip file\n",
    "# with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "#     zip_ref.extractall(extract_dir)\n",
    "\n",
    "# # Check the extracted directory structure\n",
    "# !ls {extract_dir}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = './data'\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = 4\n",
    "\n",
    "LATENT_DIMENSIONS = 100\n",
    "EPOCHS = 15\n",
    "\n",
    "LEARNING_RATE = 0.00015\n",
    "BETA1 = 0.5\n",
    "BETA2 = 0.999\n",
    "GAMMA = 0.99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:2\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:2\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['trafic_32']\n",
      "1\n",
      "39209\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "dataset = ImageFolder(root=DATA_PATH, transform=transform)\n",
    "data_loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "# train_set, val_set = torch.utils.data.random_split(dataset, [45000, 5000])\n",
    "\n",
    "print(dataset.classes)\n",
    "print(len(dataset.classes))\n",
    "print(len(dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "application/pdf": "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",
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"572.4pt\" height=\"150.822473pt\" viewBox=\"0 0 572.4 150.822473\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n",
       " <metadata>\n",
       "  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
       "   <cc:Work>\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n",
       "    <dc:date>2024-05-13T02:52:31.580893</dc:date>\n",
       "    <dc:format>image/svg+xml</dc:format>\n",
       "    <dc:creator>\n",
       "     <cc:Agent>\n",
       "      <dc:title>Matplotlib v3.8.3, https://matplotlib.org/</dc:title>\n",
       "     </cc:Agent>\n",
       "    </dc:creator>\n",
       "   </cc:Work>\n",
       "  </rdf:RDF>\n",
       " </metadata>\n",
       " <defs>\n",
       "  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M 0 150.822473 \n",
       "L 572.4 150.822473 \n",
       "L 572.4 0 \n",
       "L 0 0 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g clip-path=\"url(#p403a16e341)\">\n",
       "    <image xlink:href=\"data:image/png;base64,\n",
       "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\" id=\"image042d22075b\" transform=\"scale(1 -1) translate(0 -121.68)\" x=\"7.2\" y=\"-21.942473\" width=\"121.68\" height=\"121.68\"/>\n",
       "   </g>\n",
       "   <g id=\"text_1\">\n",
       "    <!-- Label: 0 -->\n",
       "    <g transform=\"translate(43.918736 16.318125) scale(0.12 -0.12)\">\n",
       "     <defs>\n",
       "      <path id=\"DejaVuSans-4c\" d=\"M 628 4666 \n",
       "L 1259 4666 \n",
       "L 1259 531 \n",
       "L 3531 531 \n",
       "L 3531 0 \n",
       "L 628 0 \n",
       "L 628 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-61\" d=\"M 2194 1759 \n",
       "Q 1497 1759 1228 1600 \n",
       "Q 959 1441 959 1056 \n",
       "Q 959 750 1161 570 \n",
       "Q 1363 391 1709 391 \n",
       "Q 2188 391 2477 730 \n",
       "Q 2766 1069 2766 1631 \n",
       "L 2766 1759 \n",
       "L 2194 1759 \n",
       "z\n",
       "M 3341 1997 \n",
       "L 3341 0 \n",
       "L 2766 0 \n",
       "L 2766 531 \n",
       "Q 2569 213 2275 61 \n",
       "Q 1981 -91 1556 -91 \n",
       "Q 1019 -91 701 211 \n",
       "Q 384 513 384 1019 \n",
       "Q 384 1609 779 1909 \n",
       "Q 1175 2209 1959 2209 \n",
       "L 2766 2209 \n",
       "L 2766 2266 \n",
       "Q 2766 2663 2505 2880 \n",
       "Q 2244 3097 1772 3097 \n",
       "Q 1472 3097 1187 3025 \n",
       "Q 903 2953 641 2809 \n",
       "L 641 3341 \n",
       "Q 956 3463 1253 3523 \n",
       "Q 1550 3584 1831 3584 \n",
       "Q 2591 3584 2966 3190 \n",
       "Q 3341 2797 3341 1997 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-62\" d=\"M 3116 1747 \n",
       "Q 3116 2381 2855 2742 \n",
       "Q 2594 3103 2138 3103 \n",
       "Q 1681 3103 1420 2742 \n",
       "Q 1159 2381 1159 1747 \n",
       "Q 1159 1113 1420 752 \n",
       "Q 1681 391 2138 391 \n",
       "Q 2594 391 2855 752 \n",
       "Q 3116 1113 3116 1747 \n",
       "z\n",
       "M 1159 2969 \n",
       "Q 1341 3281 1617 3432 \n",
       "Q 1894 3584 2278 3584 \n",
       "Q 2916 3584 3314 3078 \n",
       "Q 3713 2572 3713 1747 \n",
       "Q 3713 922 3314 415 \n",
       "Q 2916 -91 2278 -91 \n",
       "Q 1894 -91 1617 61 \n",
       "Q 1341 213 1159 525 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 4863 \n",
       "L 1159 4863 \n",
       "L 1159 2969 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-65\" d=\"M 3597 1894 \n",
       "L 3597 1613 \n",
       "L 953 1613 \n",
       "Q 991 1019 1311 708 \n",
       "Q 1631 397 2203 397 \n",
       "Q 2534 397 2845 478 \n",
       "Q 3156 559 3463 722 \n",
       "L 3463 178 \n",
       "Q 3153 47 2828 -22 \n",
       "Q 2503 -91 2169 -91 \n",
       "Q 1331 -91 842 396 \n",
       "Q 353 884 353 1716 \n",
       "Q 353 2575 817 3079 \n",
       "Q 1281 3584 2069 3584 \n",
       "Q 2775 3584 3186 3129 \n",
       "Q 3597 2675 3597 1894 \n",
       "z\n",
       "M 3022 2063 \n",
       "Q 3016 2534 2758 2815 \n",
       "Q 2500 3097 2075 3097 \n",
       "Q 1594 3097 1305 2825 \n",
       "Q 1016 2553 972 2059 \n",
       "L 3022 2063 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-6c\" d=\"M 603 4863 \n",
       "L 1178 4863 \n",
       "L 1178 0 \n",
       "L 603 0 \n",
       "L 603 4863 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-3a\" d=\"M 750 794 \n",
       "L 1409 794 \n",
       "L 1409 0 \n",
       "L 750 0 \n",
       "L 750 794 \n",
       "z\n",
       "M 750 3309 \n",
       "L 1409 3309 \n",
       "L 1409 2516 \n",
       "L 750 2516 \n",
       "L 750 3309 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-20\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \n",
       "Q 1547 4250 1301 3770 \n",
       "Q 1056 3291 1056 2328 \n",
       "Q 1056 1369 1301 889 \n",
       "Q 1547 409 2034 409 \n",
       "Q 2525 409 2770 889 \n",
       "Q 3016 1369 3016 2328 \n",
       "Q 3016 3291 2770 3770 \n",
       "Q 2525 4250 2034 4250 \n",
       "z\n",
       "M 2034 4750 \n",
       "Q 2819 4750 3233 4129 \n",
       "Q 3647 3509 3647 2328 \n",
       "Q 3647 1150 3233 529 \n",
       "Q 2819 -91 2034 -91 \n",
       "Q 1250 -91 836 529 \n",
       "Q 422 1150 422 2328 \n",
       "Q 422 3509 836 4129 \n",
       "Q 1250 4750 2034 4750 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "     </defs>\n",
       "     <use xlink:href=\"#DejaVuSans-4c\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-61\" x=\"55.712891\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-62\" x=\"116.992188\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-65\" x=\"180.46875\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6c\" x=\"241.992188\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-3a\" x=\"269.775391\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-20\" x=\"303.466797\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-30\" x=\"335.253906\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "  </g>\n",
       "  <g id=\"axes_2\">\n",
       "   <g clip-path=\"url(#pd201a787f6)\">\n",
       "    <image xlink:href=\"data:image/png;base64,\n",
       "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\" id=\"imagefa6a2ff57c\" transform=\"scale(1 -1) translate(0 -121.68)\" x=\"152.765217\" y=\"-21.942473\" width=\"121.68\" height=\"121.68\"/>\n",
       "   </g>\n",
       "   <g id=\"text_2\">\n",
       "    <!-- Label: 0 -->\n",
       "    <g transform=\"translate(189.483954 16.318125) scale(0.12 -0.12)\">\n",
       "     <use xlink:href=\"#DejaVuSans-4c\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-61\" x=\"55.712891\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-62\" x=\"116.992188\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-65\" x=\"180.46875\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6c\" x=\"241.992188\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-3a\" x=\"269.775391\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-20\" x=\"303.466797\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-30\" x=\"335.253906\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "  </g>\n",
       "  <g id=\"axes_3\">\n",
       "   <g clip-path=\"url(#pec6d4f79b0)\">\n",
       "    <image xlink:href=\"data:image/png;base64,\n",
       "iVBORw0KGgoAAAANSUhEUgAAAKkAAACpCAYAAABQ1R0vAAAB2klEQVR4nO3SMQEAIAzAsIF/zyCBkx6Jgh5dM3MGwvbvAHgxKXkmJc+k5JmUPJOSZ1LyTEqeSckzKXkmJc+k5JmUPJOSZ1LyTEqeSckzKXkmJc+k5JmUPJOSZ1LyTEqeSckzKXkmJc+k5JmUPJOSZ1LyTEqeSckzKXkmJc+k5JmUPJOSZ1LyTEqeSckzKXkmJc+k5JmUPJOSZ1LyTEqeSckzKXkmJc+k5JmUPJOSZ1LyTEqeSckzKXkmJc+k5JmUPJOSZ1LyTEqeSckzKXkmJc+k5JmUPJOSZ1LyTEqeSckzKXkmJc+k5JmUPJOSZ1LyTEqeSckzKXkmJc+k5JmUPJOSZ1LyTEqeSckzKXkmJc+k5JmUPJOSZ1LyTEqeSckzKXkmJc+k5JmUPJOSZ1LyTEqeSckzKXkmJc+k5JmUPJOSZ1LyTEqeSckzKXkmJc+k5JmUPJOSZ1LyTEqeSckzKXkmJc+k5JmUPJOSZ1LyTEqeSckzKXkmJc+k5JmUPJOSZ1LyTEqeSckzKXkmJc+k5JmUPJOSZ1LyTEqeSckzKXkmJc+k5JmUPJOSZ1LyTEqeSckzKXkmJc+k5JmUPJOSZ1LyTEqeSckzKXkmJc+k5JmUPJOSZ1LyTEreBR7zAlEkIjUUAAAAAElFTkSuQmCC\" id=\"imagebe69766a80\" transform=\"scale(1 -1) translate(0 -121.68)\" x=\"298.330435\" y=\"-21.942473\" width=\"121.68\" height=\"121.68\"/>\n",
       "   </g>\n",
       "   <g id=\"text_3\">\n",
       "    <!-- Label: 0 -->\n",
       "    <g transform=\"translate(335.049171 16.318125) scale(0.12 -0.12)\">\n",
       "     <use xlink:href=\"#DejaVuSans-4c\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-61\" x=\"55.712891\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-62\" x=\"116.992188\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-65\" x=\"180.46875\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6c\" x=\"241.992188\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-3a\" x=\"269.775391\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-20\" x=\"303.466797\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-30\" x=\"335.253906\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "  </g>\n",
       "  <g id=\"axes_4\">\n",
       "   <g clip-path=\"url(#p4d50f50bfd)\">\n",
       "    <image xlink:href=\"data:image/png;base64,\n",
       "iVBORw0KGgoAAAANSUhEUgAAAKkAAACpCAYAAABQ1R0vAAACCUlEQVR4nO3XsQlCQRBAwVM0sAyxBfvvRIzNzQy0AA8+gvgfOBMuF2zwWLjNGOM5IGy79gKwRKTkiZQ8kZInUvJESp5IyRMpeSIlT6TkiZQ8kZInUvJESp5IyRMpeSIlT6TkiZQ8kZInUvJESp5IyRMpeSIlT6TkiZQ8kZInUvJESp5IyRMpeSIlT6TkiZQ8kZInUvJESp5IyRMpeSIlT6TkiZQ8kZInUvJESp5IyRMpeSIlT6TkiZQ8kZInUvJESp5IyRMpeSIlT6TkiZQ8kZInUvJESp5IyRMpeSIlT6TkiZQ8kZInUvJESp5IyRMpeSIlT6TkiZQ8kZInUvJESp5IyRMpeSIlT6TkiZQ8kZInUvJESp5IyRMpeSIlT6TkiZQ8kZInUvJESp5IyRMpeSIlT6TkiZQ8kZInUvJESp5IyRMpeSIlT6TkiZQ8kZInUvJESp5IyRMpeSIlT6TkiZQ8kZInUvJESp5IyRMpeSIlT6TkiZQ8kZInUvJESp5IyRMpeSIlT6TkiZQ8kZInUvJESp5IyRMpeSIlT6TkiZQ8kZInUvJESp5IyRMpeSIlT6TkiZQ8kZInUvJESp5IyRMpeSIlT6TkiZQ8kZInUvJ2ay/Amk6T2eXnWyxxSckTKXkiJU+k5ImUPL/7v3CYTvfH89vscb1PXt6+vM9nXFLyREqeSMkTKXkvMdIHb/3gZCoAAAAASUVORK5CYII=\" id=\"imaged1fd6f5ef7\" transform=\"scale(1 -1) translate(0 -121.68)\" x=\"443.895652\" y=\"-21.942473\" width=\"121.68\" height=\"121.68\"/>\n",
       "   </g>\n",
       "   <g id=\"text_4\">\n",
       "    <!-- Label: 0 -->\n",
       "    <g transform=\"translate(480.614389 16.318125) scale(0.12 -0.12)\">\n",
       "     <use xlink:href=\"#DejaVuSans-4c\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-61\" x=\"55.712891\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-62\" x=\"116.992188\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-65\" x=\"180.46875\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6c\" x=\"241.992188\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-3a\" x=\"269.775391\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-20\" x=\"303.466797\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-30\" x=\"335.253906\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"p403a16e341\">\n",
       "   <rect x=\"7.2\" y=\"22.318125\" width=\"121.304348\" height=\"121.304348\"/>\n",
       "  </clipPath>\n",
       "  <clipPath id=\"pd201a787f6\">\n",
       "   <rect x=\"152.765217\" y=\"22.318125\" width=\"121.304348\" height=\"121.304348\"/>\n",
       "  </clipPath>\n",
       "  <clipPath id=\"pec6d4f79b0\">\n",
       "   <rect x=\"298.330435\" y=\"22.318125\" width=\"121.304348\" height=\"121.304348\"/>\n",
       "  </clipPath>\n",
       "  <clipPath id=\"p4d50f50bfd\">\n",
       "   <rect x=\"443.895652\" y=\"22.318125\" width=\"121.304348\" height=\"121.304348\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 1000x500 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def denormalize(images):\n",
    "    mean = 0.5\n",
    "    std = 0.5\n",
    "    return images * std + mean\n",
    "\n",
    "def show_images(images, labels):\n",
    "    fig, axes = plt.subplots(1, len(images), figsize=(10, 5))\n",
    "    for ax, image, label in zip(axes, images, labels):\n",
    "        # Denormalize the image\n",
    "        denorm_image = denormalize(image)\n",
    "\n",
    "        ax.imshow(denorm_image.permute(1, 2, 0))\n",
    "        ax.set_title(f\"Label: {label}\")\n",
    "        ax.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Get 4 random images from the dataset\n",
    "data_iter = iter(data_loader)\n",
    "images, labels = next(data_iter)\n",
    "\n",
    "\n",
    "# Display the images\n",
    "show_images(images[0:4], labels[0:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_dimension, hidden_dimension):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.convolution1 = nn.Conv2d(input_dimension, hidden_dimension, kernel_size=4, stride=2, padding=1)\n",
    "        self.batch_norm1 = nn.BatchNorm2d(hidden_dimension)\n",
    "        self.convolution2 = nn.Conv2d(hidden_dimension, hidden_dimension*2, kernel_size=4, stride=2, padding=1)\n",
    "        self.batch_norm2 = nn.BatchNorm2d(hidden_dimension*2)\n",
    "        self.convolution3 = nn.Conv2d(hidden_dimension*2, hidden_dimension*4, kernel_size=4, stride=2, padding=1)\n",
    "        self.batch_norm3 = nn.BatchNorm2d(hidden_dimension*4)\n",
    "        self.convolution4 = nn.Conv2d(hidden_dimension*4, 1, kernel_size=4, stride=1, padding=0)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.batch_norm1(self.convolution1(x)))\n",
    "        x = self.relu(self.batch_norm2(self.convolution2(x)))\n",
    "        x = self.relu(self.batch_norm3(self.convolution3(x)))\n",
    "        x = self.sigmoid(self.convolution4(x))\n",
    "        return x\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dimension, hidden_dimension, output_dimension):\n",
    "        super(Generator, self).__init__()\n",
    "        self.convtrans1 = nn.ConvTranspose2d(latent_dimension, hidden_dimension*4, kernel_size=4, stride=1, padding=0)\n",
    "        self.batch_norm1 = nn.BatchNorm2d(hidden_dimension*4)\n",
    "        self.convtrans2 = nn.ConvTranspose2d(hidden_dimension*4, hidden_dimension*2, kernel_size=4, stride=2, padding=1)\n",
    "        self.batch_norm2 = nn.BatchNorm2d(hidden_dimension*2)\n",
    "        self.convtrans3 = nn.ConvTranspose2d(hidden_dimension*2, hidden_dimension, kernel_size=4, stride=2, padding=1)\n",
    "        self.batch_norm3 = nn.BatchNorm2d(hidden_dimension)\n",
    "        self.convtrans4 = nn.ConvTranspose2d(hidden_dimension, output_dimension, 4, stride=2, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.batch_norm1(self.convtrans1(x)))\n",
    "        x = self.relu(self.batch_norm2(self.convtrans2(x)))\n",
    "        x = self.relu(self.batch_norm3(self.convtrans3(x)))\n",
    "        x = self.tanh(self.convtrans4(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator(LATENT_DIMENSIONS, 64, 3).to(device)\n",
    "discriminator = Discriminator(3, 64).to(device)\n",
    "\n",
    "optimizer_generator = optim.Adam(generator.parameters(), lr=0.00015, betas=(BETA1, BETA2))\n",
    "optimizer_discriminator = optim.Adam(discriminator.parameters(), lr=0.00015, betas=(BETA1, BETA2))\n",
    "\n",
    "scheduler_generator = optim.lr_scheduler.ExponentialLR(optimizer_generator, GAMMA)\n",
    "scheduler_discriminator = optim.lr_scheduler.ExponentialLR(optimizer_discriminator, GAMMA)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "noise = torch.randn(16, LATENT_DIMENSIONS, 1, 1, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected 3D (unbatched) or 4D (batched) input to conv_transpose2d, but got input of size: [32, 100]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 29\u001b[0m\n\u001b[1;32m     27\u001b[0m noise \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(b_size, LATENT_DIMENSIONS,device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Generate fake image batch with Generator\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m fake_images \u001b[38;5;241m=\u001b[39m \u001b[43mgenerator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnoise\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m label_fake \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros((b_size,), dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Classify all fake batch with Discriminator\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[28], line 30\u001b[0m, in \u001b[0;36mGenerator.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 30\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvtrans1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     31\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvtrans2(x))\n\u001b[1;32m     32\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvtrans3(x))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py:952\u001b[0m, in \u001b[0;36mConvTranspose2d.forward\u001b[0;34m(self, input, output_size)\u001b[0m\n\u001b[1;32m    947\u001b[0m num_spatial_dims \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m    948\u001b[0m output_padding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_padding(\n\u001b[1;32m    949\u001b[0m     \u001b[38;5;28minput\u001b[39m, output_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel_size,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    950\u001b[0m     num_spatial_dims, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m--> 952\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv_transpose2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    953\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    954\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_padding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected 3D (unbatched) or 4D (batched) input to conv_transpose2d, but got input of size: [32, 100]"
     ]
    }
   ],
   "source": [
    "G_losses = []\n",
    "D_losses = []\n",
    "for epoch in range(EPOCHS):\n",
    "    # For each batch in the dataloader\n",
    "    discriminator_fake_acc = []\n",
    "    discriminator_real_acc = []\n",
    "    for i, data in enumerate(data_loader, 0):\n",
    "\n",
    "        ############################\n",
    "        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
    "        ###########################\n",
    "        ## Train with all-real batch\n",
    "        optimizer_discriminator.zero_grad()\n",
    "        # Format batch\n",
    "        real_images = data[0].to(device)\n",
    "        b_size = real_images.size(0)\n",
    "        label = torch.ones((b_size,), dtype=torch.float, device=device) # Setting labels for real images\n",
    "        # Forward pass real batch through D\n",
    "        output = discriminator(real_images).view(-1)\n",
    "        # Calculate loss on all-real batch\n",
    "        error_discriminator_real = criterion(output, label)\n",
    "        # Calculate gradients for D in backward pass\n",
    "        discriminator_real_acc.append(output.mean().item())\n",
    "\n",
    "        ## Train with all-fake batch\n",
    "        # Generate batch of latent vectors\n",
    "        noise = torch.randn(b_size, LATENT_DIMENSIONS,device=device)\n",
    "        # Generate fake image batch with Generator\n",
    "        fake_images = generator(noise)\n",
    "        label_fake = torch.zeros((b_size,), dtype=torch.float, device=device)\n",
    "        # Classify all fake batch with Discriminator\n",
    "        output = discriminator(fake_images.detach()).view(-1)\n",
    "        # Calculate D's loss on the all-fake batch\n",
    "        error_discriminator_fake = criterion(output, label_fake)\n",
    "        # Calculate the gradients for this batch, accumulated (summed) with previous gradients\n",
    "        discriminator_fake_acc.append(output.mean().item())\n",
    "        # Compute error of D as sum over the fake and the real batches\n",
    "        error_discriminator = error_discriminator_real + error_discriminator_fake\n",
    "        error_discriminator.backward()\n",
    "        # Update D\n",
    "        optimizer_discriminator.step()\n",
    "\n",
    "        ############################\n",
    "        # (2) Update G network: maximize log(D(G(z)))\n",
    "        ###########################\n",
    "        optimizer_generator.zero_grad()\n",
    "        label = torch.ones((b_size,), dtype=torch.float, device=device)  # fake labels are real for generator cost\n",
    "        # Since we just updated D, perform another forward pass of all-fake batch through D\n",
    "        output = discriminator(fake_images).view(-1)\n",
    "        # Calculate G's loss based on this output\n",
    "        error_generator = criterion(output, label)\n",
    "        # Calculate gradients for G\n",
    "        error_generator.backward()\n",
    "        D_G_z2 = output.mean().item()\n",
    "        # Update G\n",
    "        optimizer_generator.step()\n",
    "\n",
    "        # Output training stats\n",
    "        # Save Losses for plotting later\n",
    "        G_losses.append(error_generator.item())\n",
    "        D_losses.append(error_discriminator.item())\n",
    "\n",
    "    print(f\"Epoch: {epoch}, discrimiantor fake error: {np.mean(discriminator_fake_acc):.3}, discriminator real acc: {np.mean(discriminator_real_acc):.3}\")\n",
    "    scheduler_generator.step()\n",
    "    scheduler_discriminator.step()\n",
    "    if epoch % 10 == 0:\n",
    "        with torch.no_grad():\n",
    "            fake = generator(noise).detach().cpu()\n",
    "        grid = torchvision.utils.make_grid(fake)\n",
    "        grid = grid.permute(1, 2, 0)\n",
    "        plt.figure(figsize=(10,10))\n",
    "        plt.title(f\"Generations\")\n",
    "        plt.imshow(grid)\n",
    "        plt.axis('off')\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

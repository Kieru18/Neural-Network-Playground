{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wstęp do przetwarzania języka naturalnego"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f759152fdd0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Średniowieczne podejścia - bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = pd.read_csv(\"http://galera.ii.pw.edu.pl/~kdeja/data/sst2.tsv\",delimiter=\"\\t\",quoting=3).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hide new secretions from the parental units</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>contains no wit , only labored gags</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>that loves its characters and communicates som...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>remains utterly satisfied to remain the same t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>on the worst revenge-of-the-nerds clichés the ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67344</th>\n",
       "      <td>a delightful comedy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67345</th>\n",
       "      <td>anguish , anger and frustration</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67346</th>\n",
       "      <td>at achieving the modest , crowd-pleasing goals...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67347</th>\n",
       "      <td>a patient viewer</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67348</th>\n",
       "      <td>this new jangle of noise , mayhem and stupidit...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67349 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sentence  label\n",
       "0           hide new secretions from the parental units       0\n",
       "1                   contains no wit , only labored gags       0\n",
       "2      that loves its characters and communicates som...      1\n",
       "3      remains utterly satisfied to remain the same t...      0\n",
       "4      on the worst revenge-of-the-nerds clichés the ...      0\n",
       "...                                                  ...    ...\n",
       "67344                               a delightful comedy       1\n",
       "67345                   anguish , anger and frustration       0\n",
       "67346  at achieving the modest , crowd-pleasing goals...      1\n",
       "67347                                  a patient viewer       1\n",
       "67348  this new jangle of noise , mayhem and stupidit...      0\n",
       "\n",
       "[67349 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on the worst revenge-of-the-nerds clichés the filmmakers could dredge up \n"
     ]
    }
   ],
   "source": [
    "print(reviews[\"sentence\"][4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/kieru/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def review_to_words(raw_review):\n",
    "    \"\"\"Function to convert a review to a string of words.\n",
    "    The input is a single string (a raw movie review), and the output is a single string (a preprocessed movie review)\"\"\"\n",
    "    review_text = BeautifulSoup(raw_review, 'lxml').get_text()\n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", review_text)\n",
    "    words = letters_only.lower().split()\n",
    "    stops = set(stopwords.words('english'))\n",
    "    meaningful_words = [word for word in words if not word in stops]\n",
    "    return \" \".join(meaningful_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "worst revenge nerds clich filmmakers could dredge\n"
     ]
    }
   ],
   "source": [
    "clean_review = review_to_words(reviews['sentence'][4])\n",
    "print(clean_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_28228/3593606712.py:4: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  review_text = BeautifulSoup(raw_review, 'lxml').get_text()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 1000 of 67349\n",
      "Review 2000 of 67349\n",
      "Review 3000 of 67349\n",
      "Review 4000 of 67349\n",
      "Review 5000 of 67349\n",
      "Review 6000 of 67349\n",
      "Review 7000 of 67349\n",
      "Review 8000 of 67349\n",
      "Review 9000 of 67349\n",
      "Review 10000 of 67349\n",
      "Review 11000 of 67349\n",
      "Review 12000 of 67349\n",
      "Review 13000 of 67349\n",
      "Review 14000 of 67349\n",
      "Review 15000 of 67349\n",
      "Review 16000 of 67349\n",
      "Review 17000 of 67349\n",
      "Review 18000 of 67349\n",
      "Review 19000 of 67349\n",
      "Review 20000 of 67349\n",
      "Review 21000 of 67349\n",
      "Review 22000 of 67349\n",
      "Review 23000 of 67349\n",
      "Review 24000 of 67349\n",
      "Review 25000 of 67349\n",
      "Review 26000 of 67349\n",
      "Review 27000 of 67349\n",
      "Review 28000 of 67349\n",
      "Review 29000 of 67349\n",
      "Review 30000 of 67349\n",
      "Review 31000 of 67349\n",
      "Review 32000 of 67349\n",
      "Review 33000 of 67349\n",
      "Review 34000 of 67349\n",
      "Review 35000 of 67349\n",
      "Review 36000 of 67349\n",
      "Review 37000 of 67349\n",
      "Review 38000 of 67349\n",
      "Review 39000 of 67349\n",
      "Review 40000 of 67349\n",
      "Review 41000 of 67349\n",
      "Review 42000 of 67349\n",
      "Review 43000 of 67349\n",
      "Review 44000 of 67349\n",
      "Review 45000 of 67349\n",
      "Review 46000 of 67349\n",
      "Review 47000 of 67349\n",
      "Review 48000 of 67349\n",
      "Review 49000 of 67349\n",
      "Review 50000 of 67349\n",
      "Review 51000 of 67349\n",
      "Review 52000 of 67349\n",
      "Review 53000 of 67349\n",
      "Review 54000 of 67349\n",
      "Review 55000 of 67349\n",
      "Review 56000 of 67349\n",
      "Review 57000 of 67349\n",
      "Review 58000 of 67349\n",
      "Review 59000 of 67349\n",
      "Review 60000 of 67349\n",
      "Review 61000 of 67349\n",
      "Review 62000 of 67349\n",
      "Review 63000 of 67349\n",
      "Review 64000 of 67349\n",
      "Review 65000 of 67349\n",
      "Review 66000 of 67349\n",
      "Review 67000 of 67349\n"
     ]
    }
   ],
   "source": [
    "num_reviews = reviews['sentence'].size\n",
    "\n",
    "# Initialize an empty list to hold the clean reviews\n",
    "clean_train_reviews = []\n",
    "\n",
    "# Loop over each review; create an index i that goes from 0 to the length of the move review list\n",
    "for review in range(0, num_reviews):\n",
    "    # If the index is evenly divisible by 100, print a message\n",
    "    if (review+1) % 1000 == 0:\n",
    "        print('Review {} of {}'.format(review+1, num_reviews))\n",
    "    # Call our function for each one, and add the result to the list of clean reviews\n",
    "    clean_train_reviews.append(review_to_words(reviews['sentence'][review]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the bag of words...\n",
      "Bag of words completed\n"
     ]
    }
   ],
   "source": [
    "print('Creating the bag of words...')\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Initialize the \"CountVectorizer\" object, which is scikit-learn's bag of words tool.\n",
    "vectorizer = CountVectorizer(analyzer = 'word',\n",
    "                            tokenizer = None,\n",
    "                            preprocessor = None,\n",
    "                            stop_words = None,\n",
    "                            max_features = 1000)\n",
    "# fit_transform() does two functions: First, it fits the model\n",
    "# and learns the vocaulary; second, it transforms our training data\n",
    "# into feature vectors. The input to fit_transform should be a list of strings.\n",
    "train_data_features = vectorizer.fit_transform(clean_train_reviews)\n",
    "\n",
    "# Numpy arrays are easy to work with, so convert the result to an array\n",
    "train_data_features = train_data_features.toarray()\n",
    "print('Bag of words completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "vocab = vectorizer.get_feature_names_out()\n",
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices = np.random.rand(len(reviews))>0.3\n",
    "train_data = torch.from_numpy(train_data_features).float()[train_indices]\n",
    "train_targets = torch.from_numpy(reviews[\"label\"].values[train_indices]).long()\n",
    "\n",
    "test_data = torch.from_numpy(train_data_features[~train_indices]).float()\n",
    "test_targets = torch.from_numpy(reviews[\"label\"].values[~train_indices]).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = data.TensorDataset(train_data,train_targets)\n",
    "test_dataset = data.TensorDataset(test_data,test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = data.DataLoader(train_dataset, batch_size=64, shuffle=True, drop_last=True)\n",
    "test_loader = data.DataLoader(test_dataset, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoWClassifier(\n",
       "  (lin1): Linear(in_features=1000, out_features=500, bias=True)\n",
       "  (act1): LeakyReLU(negative_slope=0.01)\n",
       "  (lin2): Linear(in_features=500, out_features=50, bias=True)\n",
       "  (act2): LeakyReLU(negative_slope=0.01)\n",
       "  (lin3): Linear(in_features=50, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class BoWClassifier(nn.Module):\n",
    "    def __init__(self): \n",
    "        super(BoWClassifier, self).__init__()\n",
    "        self.lin1 =nn.Linear(1000, 500)\n",
    "        self.act1 =nn.LeakyReLU()\n",
    "        self.lin2 =nn.Linear(500, 50)\n",
    "        self.act2 =nn.LeakyReLU()\n",
    "        self.lin3 =nn.Linear(50, 2)\n",
    "        \n",
    "             \n",
    "    def forward(self, x):\n",
    "        x = self.lin1(x)\n",
    "        x = self.act1(x)\n",
    "        x = self.lin2(x)\n",
    "        x = self.act2(x)\n",
    "        x = self.lin3(x)\n",
    "        return x\n",
    "bow_model = BoWClassifier().to(device)\n",
    "bow_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(model, data_loader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.eval() #*********#\n",
    "    for imgs, labels in data_loader:\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        output = model(imgs)\n",
    "        pred = output.max(1, keepdim=True)[1] # get the index of the max logit\n",
    "        correct += pred.eq(labels.view_as(pred)).sum().item()\n",
    "        total += imgs.shape[0]\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 loss 0.483 test_acc: 0.773\n",
      "Epoch 1 loss 0.385 test_acc: 0.8\n",
      "Epoch 2 loss 0.322 test_acc: 0.809\n",
      "Epoch 3 loss 0.288 test_acc: 0.812\n",
      "Epoch 4 loss 0.268 test_acc: 0.812\n",
      "Epoch 5 loss 0.258 test_acc: 0.813\n",
      "Epoch 6 loss 0.25 test_acc: 0.812\n",
      "Epoch 7 loss 0.246 test_acc: 0.814\n",
      "Epoch 8 loss 0.241 test_acc: 0.813\n",
      "Epoch 9 loss 0.238 test_acc: 0.814\n",
      "Final Training Accuracy: 0.868309620596206\n",
      "Final Validation Accuracy: 0.8138205319413373\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(bow_model.parameters(), lr=0.001)\n",
    "\n",
    "iters = []\n",
    "losses = []\n",
    "train_acc = []\n",
    "val_acc = []\n",
    "for n in range(10):\n",
    "    epoch_losses = []\n",
    "    for x, labels in iter(train_loader):\n",
    "        x, labels = x.to(device), labels.to(device)\n",
    "        bow_model.train() \n",
    "        out = bow_model(x).squeeze()           \n",
    "\n",
    "        loss = criterion(out, labels)\n",
    "        loss.backward()  \n",
    "        epoch_losses.append(loss.item())\n",
    "        optimizer.step()              \n",
    "        optimizer.zero_grad()         \n",
    "\n",
    "    loss_mean = np.array(epoch_losses).mean()\n",
    "    iters.append(n)\n",
    "    losses.append(loss_mean)\n",
    "    test_acc = get_accuracy(bow_model, test_loader)\n",
    "    print(f\"Epoch {n} loss {loss_mean:.3} test_acc: {test_acc:.3}\")\n",
    "    train_acc.append(get_accuracy(bow_model, train_loader)) # compute training accuracy \n",
    "    val_acc.append(test_acc)  # compute validation accuracy\n",
    "        \n",
    "\n",
    "print(\"Final Training Accuracy: {}\".format(train_acc[-1]))\n",
    "print(\"Final Validation Accuracy: {}\".format(val_acc[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.6111,  0.5300],\n",
       "        [-0.6111,  0.5300]], device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_1_text = \"I do not like this movie\"\n",
    "example_2_text = \"I like this movie\"\n",
    "examples = vectorizer.transform([review_to_words(example_1_text),review_to_words(example_2_text)])\n",
    "examples = torch.from_numpy(examples.toarray()).to(device).float()\n",
    "bow_model(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.7634,  2.7561],\n",
       "        [-2.7634,  2.7561]], device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_1_text = \"The topic of this movie is love\"\n",
    "example_2_text = \"I love a movie about this topic\"\n",
    "examples = vectorizer.transform([review_to_words(example_1_text),review_to_words(example_2_text)])\n",
    "examples = torch.from_numpy(examples.toarray()).to(device).float()\n",
    "bow_model(examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeddingi w języku"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 31.6/31.6MB downloaded\n"
     ]
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "corpus = api.load('text8')\n",
    "gensim_model = Word2Vec(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.13339266,  1.8876835 ,  2.6700191 , -0.69340384, -0.7490411 ,\n",
       "        1.9777726 , -0.52956545,  0.21457991,  1.6818674 ,  1.6169816 ,\n",
       "       -0.59351724, -0.54133415,  1.0678469 ,  3.6284897 ,  1.0552745 ,\n",
       "        0.14805715,  0.8235456 ,  2.1659665 , -0.48115572,  0.86099964,\n",
       "        0.6009968 , -0.15306573, -3.0095167 ,  0.6101597 , -2.3038478 ,\n",
       "        2.238226  ,  0.21856068,  3.4827077 ,  0.20567325, -0.6870403 ,\n",
       "       -0.18241686,  0.24984659, -0.7523722 ,  0.6705854 ,  1.4565288 ,\n",
       "        1.2905627 ,  0.08430897, -1.2670574 , -0.83090323, -1.1133698 ,\n",
       "       -0.38357988,  0.10765132,  0.13472192,  1.1420494 , -2.2820685 ,\n",
       "       -1.5219623 , -0.10362937, -1.2837416 ,  1.2411294 , -2.3586779 ,\n",
       "        1.833984  ,  1.2108414 , -2.5602224 ,  0.6886402 , -0.21302383,\n",
       "       -2.256714  ,  0.4328529 ,  2.635398  ,  0.22774096, -0.4935491 ,\n",
       "        1.8264734 , -2.0130975 ,  1.5820124 , -0.20700753, -1.0227681 ,\n",
       "       -2.5852447 , -0.41122225,  1.4872781 ,  2.6085248 , -1.7750188 ,\n",
       "       -0.2886712 , -2.9387946 , -1.5261353 , -1.5873281 ,  0.32555792,\n",
       "       -1.3463818 ,  2.9960012 ,  3.0950816 , -4.191436  ,  3.1762378 ,\n",
       "       -2.6714861 , -3.270873  , -2.1014931 ,  0.04280788, -0.8358774 ,\n",
       "        3.2198536 ,  1.844734  , -0.09852824, -1.3243088 , -1.5451941 ,\n",
       "        0.88366973, -1.0144442 ,  0.21024802, -1.2312213 ,  1.7764285 ,\n",
       "        0.42232126, -0.4586647 ,  0.97495633, -3.4467142 , -2.3295965 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gensim_model.wv[\"king\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('prince', 0.7349629402160645),\n",
       " ('throne', 0.7205792665481567),\n",
       " ('emperor', 0.7142632603645325),\n",
       " ('queen', 0.7050169706344604),\n",
       " ('kings', 0.7006803750991821),\n",
       " ('elector', 0.6772159934043884),\n",
       " ('aragon', 0.6701691746711731),\n",
       " ('vii', 0.6656975746154785),\n",
       " ('sultan', 0.6617438793182373),\n",
       " ('iii', 0.6609362363815308)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gensim_model.wv.most_similar(\"king\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('driver', 0.8174227476119995),\n",
       " ('motorcycle', 0.7254319787025452),\n",
       " ('cars', 0.7222384214401245),\n",
       " ('taxi', 0.7152960896492004),\n",
       " ('vehicle', 0.7065077424049377),\n",
       " ('truck', 0.6793736219406128),\n",
       " ('racing', 0.6472298502922058),\n",
       " ('automobile', 0.6344322562217712),\n",
       " ('passenger', 0.6342279314994812),\n",
       " ('audi', 0.6327622532844543)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gensim_model.wv.most_similar(\"car\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('loving', 0.6977720260620117),\n",
       " ('passion', 0.6435652375221252),\n",
       " ('me', 0.6402586102485657),\n",
       " ('affection', 0.6308778524398804),\n",
       " ('soul', 0.6307668089866638),\n",
       " ('thee', 0.626196563243866),\n",
       " ('my', 0.6122002005577087),\n",
       " ('dreams', 0.606260359287262),\n",
       " ('praise', 0.6008821129798889),\n",
       " ('grace', 0.5964429378509521)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gensim_model.wv.most_similar(\"love\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jak trenować embeddingi "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.3320,  2.3638,  0.8769,  0.1382, -0.3959]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "word_to_ix = {\"hello\": 0, \"world\": 1}\n",
    "embeds = nn.Embedding(2, 5)  # 2 words in vocab, 5 dimensional embeddings\n",
    "lookup_tensor = torch.tensor([word_to_ix[\"hello\"]], dtype=torch.long)\n",
    "hello_embed = embeds(lookup_tensor)\n",
    "print(hello_embed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Czyli wklejamy warstwę nn.Embedding uczymy tak jak powyżej i już?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continuous Bag-of-Words - przewidywanie słowa na podstawie kontekstu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['we', 'are', 'about', 'to', 'study', 'the', 'idea', 'of', 'a', 'computational', 'process.', 'computational', 'processes', 'are', 'abstract', 'beings', 'that', 'inhabit', 'computers.', 'as']\n",
      "[(['are', 'we', 'to', 'study'], 'about'), (['about', 'are', 'study', 'the'], 'to'), (['to', 'about', 'the', 'idea'], 'study')]\n"
     ]
    }
   ],
   "source": [
    "CONTEXT_SIZE = 2\n",
    "EMBEDDING_DIM = 10\n",
    "test_sentence = \"\"\"We are about to study the idea of a computational process.\n",
    "Computational processes are abstract beings that inhabit computers.\n",
    "As they evolve, processes manipulate other abstract things called data.\n",
    "The evolution of a process is directed by a pattern of rules\n",
    "called a program. People create programs to direct processes. In effect,\n",
    "we conjure the spirits of the computer with our spells.\"\"\".lower().split()\n",
    "\n",
    "ngrams = [\n",
    "    (\n",
    "        [test_sentence[i - j - 1] for j in range(CONTEXT_SIZE)] + [test_sentence[i + j + 1] for j in range(CONTEXT_SIZE)],\n",
    "        test_sentence[i]\n",
    "    )\n",
    "    for i in range(CONTEXT_SIZE, len(test_sentence)-CONTEXT_SIZE)\n",
    "]\n",
    "# Print the first 3, just so you can see what they look like.\n",
    "print(test_sentence[:20])\n",
    "print(ngrams[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = set(test_sentence)\n",
    "word_to_ix = {word: i for i, word in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NGramLanguageModeler(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, embedding_dim, context_size):\n",
    "        super(NGramLanguageModeler, self).__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.linear1 = nn.Linear(2 * context_size * embedding_dim, 128)\n",
    "        self.linear2 = nn.Linear(128, vocab_size)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        embeds = self.embeddings(inputs).view((1, -1))\n",
    "        out = F.relu(self.linear1(embeds))\n",
    "        out = self.linear2(out)\n",
    "        log_probs = F.log_softmax(out, dim=1)\n",
    "        return log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "227.12177300453186\n",
      "184.04519701004028\n",
      "145.4041930437088\n",
      "104.8639067709446\n",
      "67.1034374088049\n",
      "38.84411363303661\n",
      "22.226178288459778\n",
      "13.624894328415394\n",
      "9.197277262806892\n",
      "6.719919739291072\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "loss_function = nn.NLLLoss()\n",
    "emb_model = NGramLanguageModeler(len(vocab), EMBEDDING_DIM, CONTEXT_SIZE)\n",
    "optimizer = optim.Adam(emb_model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(10):\n",
    "    total_loss = 0\n",
    "    for context, target in ngrams:\n",
    "\n",
    "        # Prepare the inputs to be passed to the model (i.e, turn the words\n",
    "        # into integer indices and wrap them in tensors)\n",
    "        context_idxs = torch.tensor([word_to_ix[w] for w in context], dtype=torch.long)\n",
    "        emb_model.zero_grad()\n",
    "        log_probs = emb_model(context_idxs)\n",
    "        loss = loss_function(log_probs, torch.tensor([word_to_ix[target]], dtype=torch.long))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(total_loss)\n",
    "    losses.append(total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.3811,  1.9330,  0.0371, -0.5038,  1.0477, -2.0677,  1.0553, -1.6230,\n",
      "        -1.0013,  0.8436], grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(emb_model.embeddings.weight[word_to_ix[\"computer\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.2740, -0.3243, -0.1847, -1.0489, -1.1561,  0.5206,  0.9422, -2.1432,\n",
      "         0.9320, -0.9396], grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(emb_model.embeddings.weight[word_to_ix[\"computational\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1672])\n",
      "tensor([-0.2048])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    sim1 = torch.cosine_similarity(emb_model.embeddings.weight[word_to_ix[\"process\"]].unsqueeze(0),emb_model.embeddings.weight[word_to_ix[\"computational\"]].unsqueeze(0))\n",
    "    sim2 = torch.cosine_similarity(emb_model.embeddings.weight[word_to_ix[\"process\"]].unsqueeze(0),emb_model.embeddings.weight[word_to_ix[\"study\"]].unsqueeze(0))\n",
    "\n",
    "print(sim1)\n",
    "print(sim2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Śpiulkolot'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [37], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(emb_model\u001b[38;5;241m.\u001b[39membeddings\u001b[38;5;241m.\u001b[39mweight[\u001b[43mword_to_ix\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mŚpiulkolot\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m])\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Śpiulkolot'"
     ]
    }
   ],
   "source": [
    "print(emb_model.embeddings.weight[word_to_ix[\"Śpiulkolot\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([46, 10])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_model.embeddings.weight.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mini zadanie - zaimplementuj skip-gram - w odwrotną stronę\n",
    "Przewidujmy kontekst w oparciu o jedno słowo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytanie: jak duży musi być model dla prawdziwego słownika?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rozwiązywanie problemów z wykorzystaniem embeddingów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_weights = torch.FloatTensor(gensim_model.wv.vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([71290, 100])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_weights.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = nn.Embedding.from_pretrained(emb_weights)\n",
    "embedding.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = gensim_model.wv.key_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_train_reviews_tokenized = []\n",
    "for review in reviews['sentence']:\n",
    "    unknows = 0\n",
    "    all_parsed = 0\n",
    "    review_tokenized = []\n",
    "    for word in review.split():\n",
    "        all_parsed+=1\n",
    "        try:\n",
    "            review_tokenized.append(tokenizer[word.lower()])\n",
    "        except:\n",
    "            unknows +=1\n",
    "#     print(unknows/all_parsed)\n",
    "    clean_train_reviews_tokenized.append(review_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReviewDataset(Dataset):\n",
    "    def __init__(self, data,labels):\n",
    "        self.data = []\n",
    "        for d, l in zip(data,labels):\n",
    "            self.data.append((torch.from_numpy(np.array(d)).long(),torch.tensor(l).long()))\n",
    "            \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        in_data, target = self.data[idx]\n",
    "        return in_data, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = ReviewDataset(np.array(clean_train_reviews_tokenized, dtype=object)[train_indices],reviews[\"label\"].values[train_indices])\n",
    "test_data = ReviewDataset(np.array(clean_train_reviews_tokenized, dtype=object)[~train_indices],reviews[\"label\"].values[~train_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "def pad_collate(batch):\n",
    "    (xx, yy) = zip(*batch)\n",
    "    x_lens = [len(x)-1 for x in xx]\n",
    "\n",
    "    xx_pad = pad_sequence(xx, batch_first=True, padding_value=0)\n",
    "    yy = torch.stack(yy)\n",
    "    return xx_pad, yy, x_lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data, batch_size=32, collate_fn=pad_collate, shuffle=True,drop_last=True)\n",
    "test_loader = DataLoader(test_data, batch_size=32, collate_fn=pad_collate, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMRegressor(\n",
       "  (embeddings): Embedding(71290, 100)\n",
       "  (lstm): LSTM(100, 100)\n",
       "  (fc): Linear(in_features=100, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "class LSTMRegressor(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, num_layers, out_size, emb_weights, bidirectional = False):\n",
    "        super().__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        if bidirectional:\n",
    "            self.bidirectional = 2\n",
    "        else:\n",
    "            self.bidirectional = 1\n",
    "        self.embeddings = nn.Embedding.from_pretrained(emb_weights)\n",
    "        self.embeddings.requires_grad = False\n",
    "        self.lstm = nn.LSTM(input_size = input_size, hidden_size = hidden_size, num_layers = num_layers, bidirectional=bidirectional, batch_first=False)\n",
    "        self.fc = nn.Linear(hidden_size*self.bidirectional, out_size)\n",
    "        \n",
    "    def init_hidden(self, batch_size):\n",
    "        hidden = torch.zeros(self.num_layers*self.bidirectional , batch_size, self.hidden_size)\n",
    "        state = torch.zeros(self.num_layers*self.bidirectional , batch_size, self.hidden_size)\n",
    "        return hidden, state\n",
    "    \n",
    "    def forward(self, x, len_x, hidden):\n",
    "        x = self.embeddings(x)\n",
    "        x = torch.transpose(x,0,1)\n",
    "        all_outputs, hidden = self.lstm(x, hidden)\n",
    "        all_outputs = torch.transpose(all_outputs,0,1)\n",
    "        last_seq_items = all_outputs[range(all_outputs.shape[0]), len_x]\n",
    "        out = last_seq_items # torch.flatten(all_outputs,1)\n",
    "        x = self.fc(out)\n",
    "        return x, hidden\n",
    "     \n",
    "lstm_model = LSTMRegressor(100, 100, 1, 2, emb_weights).to(device)\n",
    "lstm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, loss: 0.551\n",
      "Epoch: 10, loss: 0.145\n",
      "Epoch: 20, loss: 0.1\n",
      "Epoch: 30, loss: 0.0816\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(lstm_model.parameters(), lr = 0.001)\n",
    "loss_fun = nn.CrossEntropyLoss()\n",
    "lstm_model.train()\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(31):\n",
    "    losses = 0\n",
    "    batches = 0\n",
    "    for x, targets, len_x in train_loader:\n",
    "        x = x.to(device)\n",
    "        targets = targets.to(device)\n",
    "        hidden, state = lstm_model.init_hidden(x.size(0))\n",
    "        hidden, state = hidden.to(device), state.to(device) \n",
    "        preds, _ = lstm_model(x, len_x, (hidden,state))\n",
    "        preds = preds.squeeze(1)\n",
    "        optimizer.zero_grad() \n",
    "        loss = loss_fun(preds, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses += loss.item()\n",
    "        batches +=1\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch: {epoch}, loss: {losses/batches:.3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lstm_model.load_state_dict(torch.load(\"lab_13/lstm_model_dict\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model.eval()\n",
    "with torch.no_grad():\n",
    "    preds_list = []\n",
    "    targets_list = []\n",
    "    for x, targets, len_x in test_loader:\n",
    "        x = x.to(device)\n",
    "        targets_list.append(targets.numpy())\n",
    "        targets = targets.to(device)\n",
    "        hidden, state = lstm_model.init_hidden(x.size(0))\n",
    "        hidden, state = hidden.to(device), state.to(device) \n",
    "        preds, _ = lstm_model(x, len_x, (hidden,state))\n",
    "        preds = preds.squeeze(1)\n",
    "        preds_list.append(preds.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.864\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test accuracy: {(np.argmax((np.concatenate(preds_list)),1) == np.concatenate(targets_list)).sum()/len(np.concatenate(targets_list)):.3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(lstm_model.state_dict(),\"models/lab13/lstm_model_dict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_1_text = \"I do not like this movie\"\n",
    "example_2_text = \"I like this movie\"\n",
    "example_1_tokenized = []\n",
    "for word in example_1_text.split():\n",
    "    try:\n",
    "        example_1_tokenized.append(tokenizer[word])\n",
    "    except:\n",
    "        continue\n",
    "example_2_tokenized = []\n",
    "for word in example_2_text.split():\n",
    "    try:\n",
    "        example_2_tokenized.append(tokenizer[word])\n",
    "    except:\n",
    "        continue\n",
    "hidden, state = lstm_model.init_hidden(1)\n",
    "hidden, state = hidden.to(device), state.to(device) \n",
    "preds_1,_ = lstm_model(torch.from_numpy(np.array(example_1_tokenized)).unsqueeze(0).to(device),len(example_1_tokenized)-1,(hidden,state))\n",
    "preds_2,_ = lstm_model(torch.from_numpy(np.array(example_2_tokenized)).unsqueeze(0).to(device),len(example_2_tokenized)-1,(hidden,state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.3498, -2.4868]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-3.6944,  3.5719]], device='cuda:0', grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(preds_1)\n",
    "print(preds_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arytmetyka na embeddingach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.20327657, -1.3371632 , -0.07425798,  0.73433286,  0.19710861,\n",
       "       -1.842164  , -1.6896536 ,  0.17760849,  2.1416192 ,  0.7001407 ,\n",
       "        0.39594802, -0.82978904,  1.0343374 ,  1.0447704 , -3.1818388 ,\n",
       "       -0.8613659 ,  2.2369003 , -1.5386881 ,  1.4481099 ,  0.5350605 ,\n",
       "        0.26765957,  1.0254495 ,  1.8813043 , -1.7352856 , -0.29233915,\n",
       "       -0.06325834, -0.06359205,  1.6479425 ,  0.03436931, -0.17052107,\n",
       "        0.24371852,  1.1445707 , -1.0282207 ,  1.4140178 , -2.5645301 ,\n",
       "       -0.8802483 , -0.7278783 , -2.7516909 , -1.391205  ,  0.55734885,\n",
       "        1.1868563 , -1.7004931 ,  0.97156334,  1.098507  ,  1.5320588 ,\n",
       "       -1.1591041 , -3.4128082 , -1.0134617 ,  1.2334167 , -0.3653265 ,\n",
       "       -0.05805945, -0.15668347,  2.1329446 , -2.25584   ,  1.203608  ,\n",
       "        2.4360988 , -0.5210286 , -1.3407598 ,  0.32769048, -0.17024717,\n",
       "       -0.7347759 , -0.12568958,  0.03310317, -0.00600551, -1.36539   ,\n",
       "       -0.32284328, -0.8544755 , -0.1406682 , -2.33968   , -1.6460965 ,\n",
       "        2.7520633 ,  1.3341167 , -0.69267005,  1.6357385 , -0.14314316,\n",
       "        0.9721552 ,  0.0232822 ,  1.8828523 , -0.9044013 , -0.5650203 ,\n",
       "       -1.1085882 , -1.6391046 ,  0.5182631 ,  2.7136514 , -1.0749512 ,\n",
       "       -1.3916856 ,  0.7144526 , -0.51478684,  1.6151489 ,  0.8378637 ,\n",
       "        0.82711947, -0.6378096 , -3.6858509 , -0.9347746 ,  0.72920537,\n",
       "       -1.6772337 ,  1.7023741 , -0.29815263,  1.4439485 ,  1.0995911 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gensim_model.wv[\"car\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "982"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer[\"car\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.2033, -1.3372, -0.0743,  0.7343,  0.1971, -1.8422, -1.6897,  0.1776,\n",
       "         2.1416,  0.7001,  0.3959, -0.8298,  1.0343,  1.0448, -3.1818, -0.8614,\n",
       "         2.2369, -1.5387,  1.4481,  0.5351,  0.2677,  1.0254,  1.8813, -1.7353,\n",
       "        -0.2923, -0.0633, -0.0636,  1.6479,  0.0344, -0.1705,  0.2437,  1.1446,\n",
       "        -1.0282,  1.4140, -2.5645, -0.8802, -0.7279, -2.7517, -1.3912,  0.5573,\n",
       "         1.1869, -1.7005,  0.9716,  1.0985,  1.5321, -1.1591, -3.4128, -1.0135,\n",
       "         1.2334, -0.3653, -0.0581, -0.1567,  2.1329, -2.2558,  1.2036,  2.4361,\n",
       "        -0.5210, -1.3408,  0.3277, -0.1702, -0.7348, -0.1257,  0.0331, -0.0060,\n",
       "        -1.3654, -0.3228, -0.8545, -0.1407, -2.3397, -1.6461,  2.7521,  1.3341,\n",
       "        -0.6927,  1.6357, -0.1431,  0.9722,  0.0233,  1.8829, -0.9044, -0.5650,\n",
       "        -1.1086, -1.6391,  0.5183,  2.7137, -1.0750, -1.3917,  0.7145, -0.5148,\n",
       "         1.6151,  0.8379,  0.8271, -0.6378, -3.6859, -0.9348,  0.7292, -1.6772,\n",
       "         1.7024, -0.2982,  1.4439,  1.0996])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_weights[tokenizer[\"car\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABB0AAAFICAYAAAAcfoZ9AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8WgzjOAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAj40lEQVR4nO3de5QV1Zko8H3IxcYGBIHmJSCCqEFURBTFFyJRYpKbxETNxHFEDfcaMTcJJirORPMa22RMMhPjKyZGx4mjJvFx4/iWQSUoIqgRFQQNiiAvlbe2LOn7192nW3fpwaYoLX8/11nr4/ids3fVqVd/a++qSnNzc3MAAAAA2MraFd0BAAAAoJwUHQAAAIBcKDoAAAAAuVB0AAAAAHKh6AAAAADkQtEBAAAAyIWiAwAAAJALRQcAAAAgF4oOAAAAQC7+R9EdAAAAgI+zmw48pE2fP/6R6VupJ1ufogMAAAAUqV2l6B7kZouLDps2bki+376+Y4yf/9MfMj8/+EvHxfjxi3+SzNn3O+fEeNFLy5M5Awf0qrb3t1ey29ulT4wX3Hh9MmfICV+N8SuvvJrM6dOne4w3rV+fzGnfqVOMF91xe2afBh7z2Ri/dM+dyZwBR306xotfXpnM6d+vIcZZ/Q6hdd9XPfl4MqfHPvvGeOrXTk3mjP3N1e/7Pe/8rlq2lzULFyRzuuw6JMbzrr06mbPHydW+LluWvQ56966ug9UL5idzug7ZPcYbly5J5tT33SnGb6xPL1sIIWzfqbp8Z1/6QDLnp5MO36L2LrtpZmZ7Zxw/KsbPXH1VMmfoqRNjXMs2/MAZpydzDr/sivf9nnd+Vy378cZ16fVZ37m6LjetX/ce7XWOcdYxoeXxYP3iF5M5nfrvHOOXp03NbK/fmLExXvbIjGRO7wNHx3jTxo3JnPb19TGe/lh6XzhkZHVfeO75pZl92m1w3xg/9te/JXNG7r1LjF9dtTqZ071H1xhn7cMhtN6Pa9nXV855LJnTMGJkjK/446OZ7Z3+5QNifPf0Z5I5Rx8yNMZvbkj3qUPHap9qWefLZj6c2afeow6K8a9uTO+jZ55Q3T+fv+WPyZzBX/xyjJfPyt7Xe+1f/a5/uS693X33pOp2V8t2vn5t9n7caYfqfnzln9K/zf/+UvV3aXptVTKnrluPGD/xs39J5gw/67sxrvXYknXcb3nMf+HWm5M5g75wbIyv+/OczPZO+tyIGL90793JnAGfOjrGWeuz5bp84un07xJCCMP3rP42P/n39G98zj9Uf+NVK19P5vRo2DHGL0+9L5nTb+y4ap9+cXF2n779nRjffN9fkznHjts7xmtXp4/VO3StHqenXP5gZnuNXz8sxrXs63c88HQy55jD94zxpjWrM9tr36VrjB949LlkzuEH7BbjmRf8UzJn1A9+HONHzjs3mXPghRdV8yffn9mnmT8/MsYzzvluMmf0T6r70oW/+0sy57xTDo7xGT/778z2LjvriBhfc9vsZM6Ez+8X41rOabWer2acfVYyZ/RPfxbjWo6dtRzzH5qVPuaHEMKh+1eP+7Vsd6vnP5vM6br7J2Nc675ey3XZjDkLkzmjR+wa47/931sy29vlf34xxrUcq1eseC2Z07Nntxi/9szcZE63ocNifMpF2ddSvzu3ei2VdZ3b8hq37CqV8t75oLxLBgAAABTK9AoAAAAoUMX0CgAAACAPig4AAABAPkp8TwdFBwAAACiQkQ4AAABALiqV8hYdyjuGAwAAACiUkQ4AAABQoEq78o4HUHQAAACAIrmnAwAAAJCHMt/TQdEBAAAACmR6BQAAAJCLMo90KG85BQAAACiUkQ4AAABQpBLfSNJIBwAAAChQpdKuTa8P6qKLLgqVSiV861vf2noL8w5GOgAAAECBKgWMdJg1a1a48sorw957751rO0Y6AAAAQIEq7dq16bWl1q9fH0488cRw1VVXhR133DGHJapSdAAAAIAiVSpte22hSZMmhc985jNh3LhxOSxMa6ZXAAAAwEdYU1NTaGpqavVeXV1dqKure1fuDTfcEObMmRNmzZq1TfpmpAMAAAAUqNKu0qZXY2Nj6NKlS6tXY2Pju9pZvHhx+OY3vxl+//vfhw4dOmyTZTPSAQAAAArUlidQhBDClClTwuTJk1u9lxrlMHv27LBixYowYsSI+N7bb78dHnzwwfCrX/0qNDU1hU984hNt6ss7KToAAABAkdr49IqsqRTvdOSRR4annnqq1XunnHJK2GOPPcI555yz1QsOISg6AAAAQKEqH+BmkB9E586dw7Bhw1q917Fjx9C9e/d3vb+1KDoAAABAgT7IYy8/KhQdAAAA4GNq2rRpuX6/ogMAAAAUaRtNryiCogMAAAAUyPQKAAAAIBfb6kaSRVB0AAAAgAJV2vjIzA8zRQcAAAAoUqW80yvKu2QAAABAoYx0AAAAgAKZXgEAAADkolLi6RWKDgAAAFAkIx0AAACAPJT5kZnlHcMBAAAAFMpIBwAAAChQpV15xwMoOgAAAECRSjy9QtEBAAAACmSkAwAAAJAPIx0AAACAPJR5pEN5lwwAAAAolJEOAAAAUKCK6RUAAABALtopOgAAAAA5qFTKe+cDRQcAAAAoUMVIBwAAACAXJR7pUN4lAwAAAAplpAMAAAAUyPQKAAAAIBduJAkAAADkw0gHAAAAIA9GOgAAAAD5KPFIh/KWUwAAAIBCGekAAAAABTK9AgAAAMiFR2YCAAAA+agoOgAAAAA5qLQr7/SKSnNzc3PRnQAAAICPq9kX/qhNn9/vvO9tpZ5sfeUtpwAAAACFMr0CAAAAilTi6RVbXHR44NHnku8ffsBuMV70X3/O/PzAz3wuxkunP5jM6XvIYdXveml5+nsG9Irxq3Ofymyv+7C93jevZc4f73kymfPlo/aJ8YaXFydzOvbrH+MlS1dl9mmnvj1i/Nbq15M523XdsZrz+mvpnB27xXjT+vWZ7bXv1KlF3rqMnM4xrmU9XffnOZntnfS5ETFe9eTjyZwe++wb4zlzFyVzRgwbGOOL/+PhZM53/v6gGK9dnV62EELYoWt1+dYteiGZ03ngoBivX5ten512qK7LrN8uhNa/39SH5yVzxh60R4xvuDO9nr7y6ep6enp+ersLIYQ9d69ueyvnPJbMaRgxMsbPXX9dMme3r54U46xtuOX2+/f/PDWzT//xj2Nj/MbyZcmc7Xv1jvFNBx6SzDn+kekxfnPDhsz2OnTsGON1a9LbQucuLbaDFxelc3Ye+L7f887vuuuhZ5I54w8dGuOs7bPltnnBVQ8lc34w8dAYv7R4RWafBvTvGeNNG9LbcPuO1W341VWrkznde3SN8fJZMzPb67X/qBi/tXFjMme7+voY33/KycmcI393bYybXss+dtZ1q257tazzWtZBLee0VSuz9/UeDdV9fdO6ten2Ou8Q4zdXps9pHRqq57SX7rkzs70BR306xlfdPCuZM/HY/WM8Y87CZM7oEbvG+JVXXs1sr0+f7jGu5VhWyzlm2sz5yZwxo3aP8TPPvZzZp6G79YtxVt9b9nv94heTOZ367xzjm+/7a2Z7x47bO8ZPzXspmbPXHgNivCljX2jfYl/YuHRJZnv1fXeK8W1T0+fjz4+tno9rWZ+33p9evi8cWV22eddendmnPU4+Nca1bAevz0vvnzvu0WL/zFhPIbReV2257mx5zfnkM+ntIIQQ9hla3RZq+f0e++cfJnNG/uP579tey7b+47+yr6X+/jPVa6kFN92QzBly/FdiXMv1cq3rfMVjjyZzeo48IMa1XEdkbZshtN4+515xaTJn2OmTYlzLNlXLOnjxrjsy+7Tz+GNiXMu11NKHHkjm9D308BhfdlP2OfSM46vn0IdmLUjmHLr/kBi/8GL6WmrQztVrqVqvFTcuW5rMqe/dN8aLX16ZzOnfryHGyx6ZkczpfeDoGL+xPvvabftO1Wu3TWtWJ3Pad+ma+fmyqbiRJAAAAJCLipEOAAAAQA4q7Yx0AAAAAHJQKfFIh/IuGQAAAFAoIx0AAACgSKZXAAAAAHko8/QKRQcAAAAokBtJAgAAAPkw0gEAAADIQ5lHOpS3nAIAAAAUykgHAAAAKJLpFQAAAEAeyjy9QtEBAAAACuSRmQAAAEA+jHQAAAAA8lBpV96RDuVdMgAAAKBQRjoAAABAkSqmVwAAAAA5KPP0CkUHAAAAKFDFSAcAAAAgFyUe6VDeJQMAAICPgEql0qZXrRobG8P+++8fOnfuHHr27Bm+8IUvhPnz5+e4ZIoOAAAA8LHwwAMPhEmTJoVHHnkk3HvvvWHTpk3hqKOOChs2bMitTdMrAAAAoEDb6kaSd911V6t/X3PNNaFnz55h9uzZ4bDDDsulTUUHAAAAKFKlbUWHpqam0NTU1Oq9urq6UFdX956fW7NmTQghhG7durWp/fdiegUAAAAUqNKu0qZXY2Nj6NKlS6tXY2Pje7a5efPm8K1vfSscfPDBYdiwYbktm5EOAAAAUKQ2jnSYMmVKmDx5cqv33m+Uw6RJk8LcuXPD9OnT29T2+1F0AAAAgAJV2tX+BIqUWqZStHTmmWeG22+/PTz44IOhX79+bWr7/Sg6AAAAwMdAc3Nz+MY3vhFuueWWMG3atLDLLrvk3qaiAwAAABSo0sbpFbWaNGlSuP7668Ntt90WOnfuHJYtWxZCCKFLly5h++23z6VNN5IEAACAIrWrtO1Vo8svvzysWbMmjBkzJvTp0ye+brzxxtwWzUgHAAAAKNC2GunQ3Ny8TdppSdEBAAAACtTWG0l+mCk6AAAAQJG20UiHIpR3yQAAAIBCGekAAAAABaq0K+94AEUHAAAAKFLFPR0AAACAHBjpAAAAAOTC0ysAAACAfHh6BQAAAMCWMdIBAAAACmR6BQAAAJCLSomnVyg6AAAAQJE8vQIAAADIQ6ViegUAAACQg0qJRzqUd8kAAACAQhnpAAAAAEUyvQIAAADIQ5mnVyg6AAAAQIEUHQAAAIB8lHh6RXnLKQAAAEChjHQAAACAApleAQAAAOSiUuLpFYoOAAAAUCAjHQAAAIB8KDoAAAAAeSjz9IryllMAAACAQlWam5ubi+4EAAAAfFy9+tSTbfp897322Uo92fpMrwAAAIAiVco7CUHRAQAAAApUaVfeezpscdHhrddfS76/3Y7dYvzcf/4+8/O7/d2JMV5w4/XJnCEnfDXGM+YsTOaMHrFrjF+d+1Rme92H7RXj9YtfTOZ06r9zjH/wm+nJnAu+dkiMn/jFxcmc4d/+TowfmrUgs0+H7j8kxhuXLknm1PfdKcbPPPdyMmfobv1i/Nbq1zPb267rjjF+Y/myZM72vXrHOGt9tlyXjzz+fGZ7B+47OMabNm5M5rSvr4/xfTPmJXPGjd4jxtMfS6/PQ0ZW1+X6tesz+9Rph07vm9cyZ9WTjydzeuyzb4zfXLk8s70ODb1ivHHdhmROfeeOMb7roWeSOeMPHRrjlxavyGxvQP+eMV636IVkTueBg2K8cs5jyZyGESNjvGzZq8mc3r27x3jBC0sz+zRkUN8Y3/uXZ5M5nzr4kzF+eMrZyZyDGn8a49Xz098TQghdd69+V9b+0HJfWDbz4WRO71EHxXjVyuz9qkdD9buaNqS387qO1e286bVV6ZxuPWJ8cuPUZM61U8bG+JrbZmf2acLn94vxuhcXJXM67zwwxps2prfN9vXVbfOZq6/KbG/oqRNj/Mor6e2lT5/q9vLKjPTxtc/o6vF17QvpY34IIewwqHrcv33a3GTOZ8cMi3EtyzfryfT+sv8+1f0l6/gTQutjUNawyJbDHTetX5fuU6fOMd64LHu/qu9d3a+e/9sryZzBu/SJ8dPzFydz9ty9//t+zzu/q5ZzUS3bXS3fs/jllZl96t+vIcZZx6CWx5+VT8xJ5jQMHxHjrH04hNb7cU3n44zz3nYtznu1XiP86LfpfeZ7p1X3mVqukz593v3JnDsvPDLGrz2T3qdCCKHb0Op+lXUMann8WbEifa3Ys2f1WnHTurWZ7bXvvEOMazm2ZJ0bWp4Xso4HIbQ+JmQd91se8x/9/vnJnAO+/8MY17KtrF2dPh6EEMIOXavHhNkX/iiZs99534vx3dPT1xFHH1K9jsi6Bgyh9XXg66+tSebs2K1LjGf96PvJnP2/V33/nMsezGzvJ2ccFuMFN92QzBly/FdiXMuxpZbjwdNXXp7Zpz3/99djvGZheh/tsmt1/6zlemvazPmZ7Y0ZtXuMn5r3UjJnrz0GxHjRf/05mTPwM5+L8W1Ts/8m+vzY6nV8LX9/1PJ307PX/DaZ88kJp8V45hPp9RRCCKOGV9fVS/fcmcwZcNSnMz9fNh6ZCQAAAOTC0ysAAAAAtpCRDgAAAFAk0ysAAACAPFQ8vQIAAADIg6dXAAAAALnw9AoAAAAgHyWeXlHeJQMAAAAKZaQDAAAAFMg9HQAAAIBceHoFAAAAkAs3kgQAAADyYXoFAAAAkIcyT68o75IBAAAAhTLSAQAAAArk6RUAAABAPko8vULRAQAAAApkpAMAAACQizLfSFLRAQAAAIpUKe9Ih/KWUwAAAIBCGekAAAAABaqUeKSDogMAAAAUqV15JyEoOgAAAECRjHQAAAAA8qHoAAAAAOShvDUHT68AAAAA8mGkAwAAABSpxPd0MNIBAAAAPkYuvfTSMHDgwNChQ4cwatSo8Oijj+bWlqIDAAAAFKrSxlftbrzxxjB58uRwwQUXhDlz5oR99tknHH300WHFihVba2FaUXQAAACAj4mf//znYeLEieGUU04JQ4cODVdccUWor68PV199dS7tKToAAABAgZrb+Gpqagpr165t9WpqanpXO2+99VaYPXt2GDduXHyvXbt2Ydy4ceHhhx/OZdkUHQAAAOAjrLGxMXTp0qXVq7Gx8V15q1atCm+//Xbo1atXq/d79eoVli1blkvfPL0CAAAAPsKmTJkSJk+e3Oq9urq6gnrTmqIDAAAAFKi5uW2fr6urq6nI0KNHj/CJT3wiLF++vNX7y5cvD717925bJzKYXgEAAAAFam7jf7Xabrvtwn777Rfuv//++N7mzZvD/fffHw466KA8Fs1IBwAAAChSW0c6bInJkyeHk08+OYwcOTIccMAB4V//9V/Dhg0bwimnnJJLe4oOAAAAUKBtWXQ44YQTwsqVK8P5558fli1bFoYPHx7uuuuud91ccmtRdAAAAICPkTPPPDOceeaZ26QtRQcAAAAo0OZtOdRhG1N0AAAAgAI1KzoAAAAAeShxzUHRAQAAAIpkegUAAACQizJPr2hXdAcAAACAcjLSAQAAAAq0eXN5RzooOgAAAECByjy9QtEBAAAACuRGkgAAAEAuTK8AAAAAclHigQ6eXgEAAADkw0gHAAAAKJB7OgAAAAC5cE8HAAAAIBcemQkAAADkwvQKAAAAIBdlLjp4egUAAACQCyMdAAAAoEDNbiQJAAAA5KHM0ysqzWW+TSYAAAB8yD33/NI2fX63wX23Uk+2PiMdAAAAoECbTa8AAAAA8lDm6RVbXHR4/k9/SL4/+EvHxfjZa36b+flPTjgtxtO//c1kziG/+LcYz5izMJkzesSuMV7wQvZQlCGDqsNMFt1xezJn4DGfjfG9f3k2mfOpgz8Z43nXXp3M2ePkU2P82jNzM/vUbeiwGNeyPm+864lkzgnjh8f41VWrM9vr3qNrjF+ZMT2Z02f0ITGe+rVTkzljf1Nd7qx+h9C67/MWLEnm7DFkpxg3vbYqmVPXrUeMH/zGpGTOYZdcGuNVK1/P7FOPhh1j/OaGDcmcDh07xvj5W/6YzBn8xS/H+K2NGzPb266+PsY33/fXZM6x4/aOcdb20nJbue7PczLbO+lzI2JcS99feHFZMmfQzr1jPO30/5XMGXPFr2P86PfPz+zTAd//YYx/9Nv0dve906rb3W1Tn0rmfH7sXjFeNvPhzPZ6jzooxm+sT//G23eq/sbLZ81M5vTaf1S1vUdmZLd34OgYz77on5M5+537jzFes3BBMqfLrkNifMOdjydzvvLpfWN8xR8fzezT6V8+IMZLlqb3q536VverTRvT66l9fXU9rZzzWGZ7DSNGxjjrGNTy+PPI488ncw7cd3CMr78jvQ5CCOGrx1TXwx0PPJ3MOebwPWNcy3YwZ+6iZM6IYQNj/Nbq7GPLdl2rx5Za+vTSvXcncwZ86ugYb9qwPrO99h07xfixv/4tmTNy711iXMuxpdZj5633p49lXziyeixbPT99Du26e/Uc+sh55yZzDrzwohi/uXJ5Zp86NPSK8fN/eyWZM3iXPjF+5uqrkjlDT50Y49Wvr81sr+uOO8T4xbvuSObsPP6YGK9dvS6Zs0PXzjGecvmDme01fv2wGH/1x1OTOdf/09gYr1uTbq9zl2p7tRzzlzzw35l92unwI2L889+nj8OTT6weg2s5nv/46r9ktvdPpx4c41r6/m//+Ugy55t/d2CMa12+P97zZDLny0ftE+OHp5ydzDmo8acxnnH2Wcmc0T/9WYyz1mUIrdfnHV/6UjLnmD/9KcYnXZjeVq47r7qt/OA36XNxCCFc8LXq+fj4H96fzLnp/CNjXMu+nvW7hND6t6nlHFrLvrdxXfqYX9+5esxf/PLKzD7179cQ4z/cnd4Ojju6uh1sWp/e99p3qu57TRuyrxXrOlavFTcuS/8tU9+7+ndMLdctr85N73shhNB9WHX/e3NVej106FFdB6sXzE/mdB2ye4xr+Ttm1zPS22YIISy8rLp9PvH0i8mc4XvunPl5PjqMdAAAAIAClflWi4oOAAAAUCDTKwAAAIBcuJEkAAAAkIsSD3QI7YruAAAAAFBORjoAAABAgdzTAQAAAMiFezoAAAAAufDITAAAACAXJR7ooOgAAAAARSrzSAdPrwAAAAByYaQDAAAAFMjTKwAAAIBceHoFAAAAkIsSD3RQdAAAAIAimV4BAAAA5MLTKwAAAAC2kJEOAAAAUCA3kgQAAAByUeKag6IDAAAAFKnM93RQdAAAAIACeXoFAAAAkIsS1xw8vQIAAADIh5EOAAAAUCBPrwAAAABy4Z4OAAAAQC5KXHNQdAAAAIAiGekAAAAA5KK5xEUHT68AAAAAcmGkAwAAABSoxA+vUHQAAACAInlkJgAAAJCLEt/SwT0dAAAAoEibm5vb9MrDokWLwmmnnRZ22WWXsP3224fBgweHCy64ILz11ltb9D1GOgAAAECBPoxPr5g3b17YvHlzuPLKK8Ouu+4a5s6dGyZOnBg2bNgQLr744pq/R9EBAAAAaGX8+PFh/Pjx8d+DBg0K8+fPD5dffrmiAwAAAHxUfFTuI7lmzZrQrVu3LfqMogMAAAAUqK33ZWhqagpNTU2t3qurqwt1dXVt+t6WFi5cGC655JItGuUQghtJAgAAQKGaN7ft1djYGLp06dLq1djYmGzr3HPPDZVK5T1f8+bNa/WZJUuWhPHjx4fjjjsuTJw4cYuWzUgHAAAAKFBbRzpMmTIlTJ48udV7WaMczjrrrDBhwoT3/L5BgwbFeOnSpeGII44Io0ePDr/+9a+3uG+KDgAAAFCgtj68YkumUjQ0NISGhoaacpcsWRKOOOKIsN9++4Xf/e53oV27LZ8soegAAAAAtLJkyZIwZsyYsPPOO4eLL744rFy5Mv6/3r171/w9ig4AAABQoLZOr8jDvffeGxYuXBgWLlwY+vXr1+r/NW9Bf91IEgAAAAq0ubltrzxMmDAhNDc3J19bwkgHAAAAKNCW/iH/UaLoAAAAAAX6ME6v2FoUHQAAAKBAJa45uKcDAAAAkA8jHQAAAKBAm/O6G+SHgKIDAAAAFKjENQdFBwAAAChSme/poOgAAAAABfL0CgAAACAXJa45eHoFAAAAkA8jHQAAAKBAplcAAAAAufD0CgAAACAXzUY6AAAAAHko80iHSnOZSyoAAADwIXfRtX9p0+fPPfngrdSTrc/TKwAAAIBcmF4BAAAABdq8uege5GeLiw6b1q9Lvt++U+cYz7vumszP73HShGretVenc04+NcYPzVqQzDl0/yExXrXy9cz2ejTsGOM3li9L5mzfq3eM7/3Ls8mcTx38yRi/cOvNyZxBXzg2xm+9/lpmn7bbsVuMF7+8MpnTv19D9bs2bkx/T319jF9avCKzvQH9e8Z40R23J3MGHvPZGN938j8kc8Zd++8x3rRmdWZ77bt0jXEtfV86/cFkTt9DDovxsmWvJnN69+4e40k/n5bZp0snj4nxc88vTebsNrhvjDeu25DMqe/cMcavPvVkZnvd99onxuddkV6+C0+vLl8t7b2xPp0TQgjbd6rmvXTPncmcAUd9OsbrFr2QzOk8cFCMn73mt8mcT044LcZrFqb3zxBC6LJrdR+96uZZyZyJx+4f400b08vXvr66bOvXrs9sr9MOnWI8Z+6iZM6IYQNjXMu2mbWvh9B6f1+/+MV0n/rvHONVTz6ezOmxz74xvua22cmcCZ/fL8bf+MW0zD5d8u0xMV7x2KPJnJ4jD9iinNXz08fEEELounv1uFjL77fgxuuTOUNO+GqM39yQvZ136Fj9rlr246y+t+p3Dee0rN83hNa/8aaMbap9y2P1vXcncwZ86ugY17qvX3LDzGTON74yKsaPX/yTZM6+3zmn2l7GuTGE1ufHrP2v5b731ur0+Xi7rtVz8atzn0rmdB+2V4xfeSV9zA8hhD59qsf9f7luRjLnuyeNrvaphn19xpyFme2NHrFrjGv5jX9zy2PJnK99cWSMb5uaXgchhPD5sdX18PT8xcmcPXfvH+Pbp81N5nx2zLAYZ52zW56vaz2n1XKdNP2x9LnhkJHV80LW8S6E1se8rG2h5XZQ0zk7Y7sLofW2V8ux7Omrrkjm7Dnx9Bg/dekvkzl7Tfo/Mb7spvQ+HEIIZxxf3Y8fmPT1ZM7hl14e49N+MjWZ89tzxsa41nPofTPmJXPGjd4jxrWcP26+76+Z7R07bu8Yz77wR8mc/c77XozXvpDeR3cYVN0/31y5PJnToaFXjKfNnJ/ZpzGjdo/xH+5O7w/HHV3dF1Y+MSeZ0zB8RIwfePS5zPYOP2C3GNeynTe9tiqZU9etR4xfnnpfZnv9xo6LcS3Hsk0b0ttL+47VbaWWc/FdDz2T2afxhw6N8cwn0temo4YPSr5fRmW+p4ORDgAAAFCgMt9qUdEBAAAACmSkAwAAAJCLzSUe6eDpFQAAAEAujHQAAACAApV4oIOiAwAAABTJPR0AAACAXJT5ng6KDgAAAFCgEtccFB0AAACgSGWeXuHpFQAAAEAujHQAAACAAjWXeH6FogMAAAAUqMzTKxQdAAAAoECKDgAAAEAuPDITAAAAyEWJaw6eXgEAAADkw0gHAAAAKNDmzUX3ID+KDgAAAFAgN5IEAAAActFc4ps6KDoAAABAgco80sGNJAEAAIBcGOkAAAAABSrzSAdFBwAAAChQiW/poOgAAAAARdpc4qqDogMAAAAUyPQKAAAAIBdlLjp4egUAAACQCyMdAAAAoEBlHumg6AAAAAAFKvF9JBUdAAAAoEhGOgAAAAC58MhMAAAAIBdlHung6RUAAABALox0AAAAgAKVeaSDogMAAAAUSNEBAAAAyEWJ7yOp6AAAAABFMtIBAAAAyEWZiw6eXgEAAADkQtEBAAAACrS5uW2vvDU1NYXhw4eHSqUSnnjiiS36rKIDAAAAFGjz5ra98nb22WeHvn37fqDPKjoAAABAgT7MIx3uvPPOcM8994SLL774A33ejSQBAACgQG0tHDQ1NYWmpqZW79XV1YW6uro2fe/y5cvDxIkTw6233hrq6+s/0HcY6QAAAAAFautIh8bGxtClS5dWr8bGxjb1qbm5OUyYMCGcfvrpYeTIkR/4exQdAAAA4CNsypQpYc2aNa1eU6ZMSeaee+65oVKpvOdr3rx54ZJLLgnr1q3L/J5amV4BAAAABXq7jdMrtmQqxVlnnRUmTJjwnjmDBg0KU6dODQ8//PC7vnfkyJHhxBNPDNdee21N7Sk6AAAAQIG2xWMv/7+GhobQ0NDwvnm//OUvw49//OP476VLl4ajjz463HjjjWHUqFE1t6foAAAAAAXalkWHWg0YMKDVvzt16hRCCGHw4MGhX79+NX+PogMAAAAU6MNYdNhaFB0AAACgQG29p8O2MHDgwNDcvOUd9fQKAAAAIBdGOgAAAECBTK8AAAAAcvFRmF7xQSk6AAAAQIGMdAAAAAByYaQDAAAAkIsyFx08vQIAAADIhZEOAAAAUKC3N1eK7kJuKs3NzSUeyAEAAAAfbrueMbVNn1942dit1JOtT9EBAAAAyIV7OgAAAAC5UHQAAAAAcqHoAAAAAORC0QEAAADIhaIDAAAAkAtFBwAAACAXig4AAABALhQdAAAAgFwoOgAAAAC5+H+RMBlDmeKSygAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1500x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,4))\n",
    "sns.heatmap([gensim_model.wv[\"king\"], \n",
    "             gensim_model.wv[\"man\"], \n",
    "             gensim_model.wv[\"woman\"], \n",
    "             gensim_model.wv[\"king\"] - gensim_model.wv[\"man\"] + gensim_model.wv[\"woman\"],\n",
    "             gensim_model.wv[\"queen\"],\n",
    "            ], cbar=True, xticklabels=False, yticklabels=False,linewidths=1,cmap=\"vlag\") \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = gensim_model.wv[\"paris\"] + gensim_model.wv[\"germany\"] - gensim_model.wv[\"berlin\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.6626449 , -0.31117308,  0.20915104, -0.7257631 ,  0.6381916 ,\n",
       "        1.7852855 , -3.39412   ,  4.004383  ,  1.9058394 ,  1.7104747 ,\n",
       "       -0.92319447, -1.7824296 , -0.9651712 ,  0.9087151 , -0.54452527,\n",
       "       -1.052601  , -1.8190565 , -2.6259663 , -0.8138212 ,  0.26190984,\n",
       "        0.13987489,  1.5264757 , -1.135104  ,  0.5918043 ,  0.28018445,\n",
       "        1.9295578 , -0.66119754,  0.95267045, -0.23843634,  0.6051739 ,\n",
       "       -2.2989872 , -0.38280356, -0.3500054 ,  2.1507523 , -1.6565998 ,\n",
       "        2.7201958 ,  1.4916588 , -4.222001  , -0.58255756, -1.027005  ,\n",
       "       -0.07382348,  0.4174245 , -1.9609661 ,  0.5525418 , -1.624783  ,\n",
       "        0.8132373 , -0.6735233 ,  0.3410684 , -1.1790097 , -2.1663675 ,\n",
       "        1.7396708 ,  3.1968186 ,  0.5951371 ,  1.5035024 ,  3.1089654 ,\n",
       "        0.96239066,  0.8791715 ,  1.3467505 , -0.29088092,  1.2826053 ,\n",
       "        0.34221882, -0.38619182, -0.16236794, -0.19734773, -1.0167805 ,\n",
       "       -2.787023  ,  2.2104473 ,  1.5850219 ,  1.4624876 ,  0.37302387,\n",
       "        0.03959155, -0.04079831, -1.0612869 ,  0.04022011,  2.5559862 ,\n",
       "       -1.1576232 ,  0.3153894 ,  2.3231964 , -0.8518163 ,  1.4506536 ,\n",
       "       -0.5007354 ,  0.6407836 ,  0.61932737,  4.4669094 , -1.202393  ,\n",
       "       -0.52909726,  4.4489202 , -0.8977519 , -2.7002757 ,  0.16243964,\n",
       "       -0.30271244,  0.93063784, -1.0577925 , -4.0618362 ,  2.5447736 ,\n",
       "       -1.2503383 ,  0.48450834, -0.68385553,  2.845869  , -0.28390723],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.9813531 ,  0.82840466,  0.821929  , -2.144536  ,  0.32480264,\n",
       "        2.5483463 , -0.8243572 ,  3.6620412 ,  0.9843587 ,  1.137295  ,\n",
       "        0.6883987 , -0.3339095 , -1.2547622 ,  0.41545793, -0.3020925 ,\n",
       "        0.0474313 , -1.199551  , -0.23994805, -1.0854532 , -0.6821749 ,\n",
       "       -0.05693669,  1.499424  , -2.0554476 ,  1.5389916 , -0.383668  ,\n",
       "        2.3863466 , -0.8027859 ,  2.1822736 ,  0.11701371, -0.8220057 ,\n",
       "       -1.2965312 , -1.1488305 ,  0.7601222 ,  1.455611  , -0.8209637 ,\n",
       "        0.57556015,  0.72745115, -2.8554003 , -0.62800545, -0.03839626,\n",
       "        0.1121708 , -0.17735457, -1.0071102 ,  0.97862536, -0.7834279 ,\n",
       "        2.238006  ,  0.34443474, -0.74529994, -1.2783973 , -1.787315  ,\n",
       "        1.9288611 ,  2.48244   ,  0.2469941 ,  0.84175223,  2.6366007 ,\n",
       "        0.3842469 ,  0.40320766,  1.0027941 ,  1.1973574 ,  0.6309989 ,\n",
       "       -0.38348216, -0.7503607 ,  0.45243138, -1.0583626 , -0.19227935,\n",
       "       -1.6162837 ,  2.2798598 ,  1.8604559 ,  0.32648   , -0.6682531 ,\n",
       "       -0.729293  , -0.20715883, -0.4001139 , -0.06215647,  2.5997317 ,\n",
       "       -1.1880594 , -0.44301698,  2.362072  , -1.5650715 ,  1.019013  ,\n",
       "        1.1202716 , -0.11241172,  0.374856  ,  4.3878555 ,  0.31252575,\n",
       "        0.10055289,  3.0471241 , -0.30705643, -1.9038986 , -1.2568394 ,\n",
       "        0.3578483 , -0.29341036,  0.18846102, -2.3044946 ,  2.4773824 ,\n",
       "       -0.4961004 , -0.15861936, -1.2653985 ,  0.81072074, -1.3832034 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gensim_model.wv[\"france\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mini zadanie: Jak możemy znaleźć do czego odnosi się wektor x?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
